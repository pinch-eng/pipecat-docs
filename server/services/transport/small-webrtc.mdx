---
title: "SmallWebRTCTransport"
description: "A lightweight WebRTC transport for peer-to-peer audio and video communication in Pipecat"
---

## Overview

SmallWebRTCTransport enables peer-to-peer ("serverless") WebRTC connections between clients and your Pipecat application. It implements bidirectional audio, video and data channels using WebRTC for real-time communication. This transport is open source and self-contained, with no dependencies on any other infrastructure.

SmallWebRTCTransport is the default transport for the Pipecat examples and starter kits. It is heavily tested and can be used in production.

<Tip>
  For detailed notes on how to decide between using the SmallWebRTCTransport or
  other WebRTC transports like the DailyTransport, see [this
  post](https://www.daily.co/blog/you-dont-need-a-webrtc-server-for-your-voice-agents/).
</Tip>

## Installation

To use `SmallWebRTCTransport`, install the required dependencies:

```bash
pip install pipecat-ai[webrtc]
```

## Class Reference

### SmallWebRTCConnection

`SmallWebRTCConnection` manages the WebRTC connection details, peer connection state, and ICE candidates. It handles the signaling process and media tracks.

```python
SmallWebRTCConnection(ice_servers=None)
```

<ParamField
  path="ice_servers"
  type="Union[List[str], List[IceServer]]"
  optional
>
  List of STUN/TURN server URLs for ICE connection establishment. Can be
  provided as strings or as IceServer objects.
</ParamField>

#### Methods

<ResponseField name="initialize" type="async method">
  Initialize the connection with a client's SDP offer.

**Parameters:**

- `sdp`: String containing the Session Description Protocol data from client's offer
- `type`: String representing the SDP message type (typically "offer")

```python
await webrtc_connection.initialize(sdp=client_sdp, type="offer")
```

</ResponseField>

<ResponseField name="connect" type="async method">
  Establish the WebRTC peer connection after initialization.

```python
await webrtc_connection.connect()
```

</ResponseField>

<ResponseField name="close" type="async method">
  Close the WebRTC peer connection.

```python
await webrtc_connection.close()
```

</ResponseField>

<ResponseField name="disconnect" type="async method">
  Disconnect the WebRTC peer connection and send a peer left message to the client.

```python
await webrtc_connection.disconnect()
```

</ResponseField>

<ResponseField name="renegotiate" type="async method">
  Handle connection renegotiation requests.

**Parameters:**

- `sdp`: String containing the Session Description Protocol data for renegotiation
- `type`: String representing the SDP message type
- `restart_pc`: Boolean indicating whether to completely restart the peer connection (default: False)

```python
await webrtc_connection.renegotiate(sdp=new_sdp, type="offer", restart_pc=False)
```

</ResponseField>

<ResponseField name="get_answer" type="method">
  Retrieve the SDP answer to send back to the client.
  
  Returns a dictionary with `sdp`, `type`, and `pc_id` fields.

```python
answer = webrtc_connection.get_answer()
# Returns: {"sdp": "...", "type": "answer", "pc_id": "..."}
```

</ResponseField>

<ResponseField name="send_app_message" type="method">
  Send an application message to the client.

**Parameters:**

- `message`: The message to send (will be JSON serialized)

```python
webrtc_connection.send_app_message({"action": "greeting", "text": "Hello!"})
```

</ResponseField>

<ResponseField name="is_connected" type="method">
  Check if the connection is active.

```python
if webrtc_connection.is_connected():
    print("Connection is active")
```

</ResponseField>

<ResponseField name="audio_input_track" type="method">
  Get the audio input track from the client.

```python
audio_track = webrtc_connection.audio_input_track()
```

</ResponseField>

<ResponseField name="video_input_track" type="method">
  Get the video input track from the client.

```python
video_track = webrtc_connection.video_input_track()
```

</ResponseField>

<ResponseField name="replace_audio_track" type="method">
  Replace the current audio track with a new one.

**Parameters:**

- `track`: The new audio track to use

```python
webrtc_connection.replace_audio_track(new_audio_track)
```

</ResponseField>

<ResponseField name="replace_video_track" type="method">
  Replace the current video track with a new one.

**Parameters:**

- `track`: The new video track to use

```python
webrtc_connection.replace_video_track(new_video_track)
```

</ResponseField>

<ResponseField name="ask_to_renegotiate" type="method">
  Request the client to initiate connection renegotiation.

```python
webrtc_connection.ask_to_renegotiate()
```

</ResponseField>

<ResponseField name="event_handler" type="decorator">
  Register an event handler for connection events.

**Events:**

- `"app-message"`: Called when a message is received from the client
- `"track-started"`: Called when a new track is started
- `"track-ended"`: Called when a track ends
- `"connecting"`: Called when connection is being established
- `"connected"`: Called when connection is established
- `"disconnected"`: Called when connection is lost
- `"closed"`: Called when connection is closed
- `"failed"`: Called when connection fails
- `"new"`: Called when a new connection is created

```python
@webrtc_connection.event_handler("connected")
async def on_connected(connection):
    print(f"WebRTC connection established")
```

</ResponseField>

### SmallWebRTCTransport

`SmallWebRTCTransport` is the main transport class that manages both input and output transports for WebRTC communication.

```python
SmallWebRTCTransport(
    webrtc_connection: SmallWebRTCConnection,
    params: TransportParams,
    input_name: Optional[str] = None,
    output_name: Optional[str] = None
)
```

<ParamField path="webrtc_connection" type="SmallWebRTCConnection" required>
  An instance of `SmallWebRTCConnection` that manages the WebRTC connection
</ParamField>

<ParamField path="params" type="TransportParams" required>
  Configuration parameters for the transport
  <Expandable title="TransportParams properties">
    <ParamField path="audio_in_enabled" type="bool" default={false}>
      Enable audio input from the WebRTC client
    </ParamField>

    <ParamField path="audio_in_passthrough" type="bool" default="False">
      When enabled, incoming audio frames are pushed downstream
    </ParamField>

    <ParamField path="audio_out_enabled" type="bool" default={false}>
      Enable audio output to the WebRTC client
    </ParamField>

    <ParamField path="audio_in_sample_rate" type="int" optional>
      Sample rate for incoming audio (Hz)
    </ParamField>

    <ParamField path="audio_out_sample_rate" type="int" optional>
      Sample rate for outgoing audio (Hz)
    </ParamField>

    <ParamField path="audio_in_channels" type="int" default={1}>
      Number of audio input channels (1 for mono, 2 for stereo)
    </ParamField>

    <ParamField path="audio_out_channels" type="int" default={1}>
      Number of audio output channels (1 for mono, 2 for stereo)
    </ParamField>

    <ParamField path="video_in_enabled" type="bool" default={false}>
      Enable video input from the WebRTC client
    </ParamField>

    <ParamField path="video_out_enabled" type="bool" default={false}>
      Enable video output to the WebRTC client
    </ParamField>

    <ParamField path="video_out_width" type="int" default={640}>
      Width of outgoing video
    </ParamField>

    <ParamField path="video_out_height" type="int" default={480}>
      Height of outgoing video
    </ParamField>

    <ParamField path="video_out_framerate" type="int" default={30}>
      Framerate of outgoing video
    </ParamField>

    <ParamField path="vad_analyzer" type="VADAnalyzer" optional>
      Custom VAD analyzer implementation
    </ParamField>

  </Expandable>
</ParamField>

<ParamField path="input_name" type="str" optional>
  Optional name for the input transport
</ParamField>

<ParamField path="output_name" type="str" optional>
  Optional name for the output transport
</ParamField>

#### Methods

<ResponseField name="input" type="method">
  Returns the input transport instance.

```python
input_transport = webrtc_transport.input()
```

</ResponseField>

<ResponseField name="output" type="method">
  Returns the output transport instance.

```python
output_transport = webrtc_transport.output()
```

</ResponseField>

<ResponseField name="send_image" type="async method">
  Send an image frame to the client.

**Parameters:**

- `frame`: The image frame to send (OutputImageRawFrame or SpriteFrame)

```python
await webrtc_transport.send_image(image_frame)
```

</ResponseField>

<ResponseField name="send_audio" type="async method">
  Send an audio frame to the client.

**Parameters:**

- `frame`: The audio frame to send (OutputAudioRawFrame)

```python
await webrtc_transport.send_audio(audio_frame)
```

</ResponseField>

#### Event Handlers

<ResponseField name="on_app_message" type="async callback">
  Called when receiving application messages from the client.

**Parameters:**

- `message`: The received message

```python
@webrtc_transport.event_handler("on_app_message")
async def on_app_message(message):
    print(f"Received message: {message}")
```

</ResponseField>

<ResponseField name="on_client_connected" type="async callback">
  Called when a client successfully connects.

**Parameters:**

- `transport`: The SmallWebRTCTransport instance
- `webrtc_connection`: The connection that was established

```python
@webrtc_transport.event_handler("on_client_connected")
async def on_client_connected(transport, webrtc_connection):
    print(f"Client connected")
```

</ResponseField>

<ResponseField name="on_client_disconnected" type="async callback">
  Called when a client disconnects.

**Parameters:**

- `transport`: The SmallWebRTCTransport instance
- `webrtc_connection`: The connection that was disconnected

```python
@webrtc_transport.event_handler("on_client_disconnected")
async def on_client_disconnected(transport, webrtc_connection):
    print(f"Client disconnected")
```

</ResponseField>

<ResponseField name="on_client_closed" type="async callback">
  Called when a client connection is closed.

**Parameters:**

- `transport`: The SmallWebRTCTransport instance
- `webrtc_connection`: The connection that was closed

```python
@webrtc_transport.event_handler("on_client_closed")
async def on_client_closed(transport, webrtc_connection):
    print(f"Client connection closed")
```

</ResponseField>

## Basic Usage

This basic usage example shows the transport specific parts of a bot.py file required to configure your bot:

```python
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.pipeline.pipeline import Pipeline
from pipecat.transports.base_transport import TransportParams
from pipecat.transports.network.small_webrtc import SmallWebRTCTransport
from pipecat.transports.network.webrtc_connection import SmallWebRTCConnection

async def run_bot(webrtc_connection):
    # Create the WebRTC transport with the provided connection
    transport = SmallWebRTCTransport(
        webrtc_connection=webrtc_connection,
        params=TransportParams(
            audio_in_enabled=True,   # Accept audio from the client
            audio_out_enabled=True,  # Send audio to the client
            vad_analyzer=SileroVADAnalyzer(),
        ),
    )

    # Set up your services and context

    # Create the pipeline
    pipeline = Pipeline([
        transport.input(),              # Receive audio from client
        stt,                            # Convert speech to text
        context_aggregator.user(),      # Add user messages to context
        llm,                            # Process text with LLM
        tts,                            # Convert text to speech
        transport.output(),             # Send audio responses to client
        context_aggregator.assistant(), # Add assistant responses to context
    ])

    # Register event handlers
    @transport.event_handler("on_client_connected")
    async def on_client_connected(transport, client):
        logger.info("Client connected")
        # Start the conversation when client connects
        await task.queue_frames([context_aggregator.user().get_context_frame()])

    @transport.event_handler("on_client_disconnected")
    async def on_client_disconnected(transport, client):
        logger.info("Client disconnected")

    @transport.event_handler("on_client_closed")
    async def on_client_closed(transport, client):
        logger.info("Client closed")
        await task.cancel()
```

## How to connect with `SmallWebRTCTransport`

For a client/server connection, you have two options for how to connect the client to the server:

1. Use a Pipecat client SDK with the `SmallWebRTCTransport`. See the [Client SDK docs](/client/js/transports/small-webrtc) to get started.
2. Using the WebRTC API directly. This is only recommended for advanced use cases where the Pipecat client SDKs don't have an available transport.

## Examples

To see a complete implementation, check out the following examples:

<CardGroup>
  <Card
    title="Video Transform"
    icon="camera"
    href="https://github.com/pipecat-ai/pipecat/tree/main/examples/p2p-webrtc/video-transform"
  >
    Demonstrates real-time video processing using WebRTC transport
  </Card>
  <Card
    title="Voice Agent"
    icon="microphone"
    href="https://github.com/pipecat-ai/pipecat/tree/main/examples/p2p-webrtc/voice-agent"
  >
    Implements a voice assistant using WebRTC for audio communication
  </Card>
</CardGroup>

## Media Handling

### Audio

Audio is processed in 20ms chunks by default. The transport handles audio format conversion and resampling as needed:

- Input audio is processed at 16kHz (mono) to be compatible with speech recognition services
- Output audio can be configured to match your application's requirements, but it must be mono, 16-bit PCM audio

### Video

Video is streamed using RGB format by default. The transport provides:

- Frame conversion between different color formats (RGB, YUV, etc.)
- Configurable resolution and framerate

## WebRTC ICE Servers Configuration

When implementing WebRTC in your project, **STUN** (Session Traversal Utilities for NAT) and **TURN** (Traversal Using Relays around NAT)
servers are usually needed in cases where users are behind routers or firewalls.

In local networks (e.g., testing within the same home or office network), you usually don't need to configure STUN or TURN servers.
In such cases, WebRTC can often directly establish peer-to-peer connections without needing to traverse NAT or firewalls.

### What are STUN and TURN Servers?

- **STUN Server**: Helps clients discover their public IP address and port when they're behind a NAT (Network Address Translation) device (like a router).
  This allows WebRTC to attempt direct peer-to-peer communication by providing the public-facing IP and port.

- **TURN Server**: Used as a fallback when direct peer-to-peer communication isn't possible due to strict NATs or firewalls blocking connections.
  The TURN server relays media traffic between peers.

### Why are ICE Servers Important?

**ICE (Interactive Connectivity Establishment)** is a framework used by WebRTC to handle network traversal and NAT issues.
The `iceServers` configuration provides a list of **STUN** and **TURN** servers that WebRTC uses to find the best way to connect two peers.

## Advanced Configuration

### ICE Servers

For better connectivity, especially when testing across different networks, you can provide STUN servers:

```python
webrtc_connection = SmallWebRTCConnection(
    ice_servers=["stun:stun.l.google.com:19302", "stun:stun1.l.google.com:19302"]
)
```

You can also use IceServer objects for more advanced configuration:

```python
from pipecat.transports.network.webrtc_connection import IceServer

webrtc_connection = SmallWebRTCConnection(
    ice_servers=[
        IceServer(urls="stun:stun.l.google.com:19302"),
        IceServer(
            urls="turn:turn.example.com:3478",
            username="username",
            credential="password"
        )
    ]
)
```

## Troubleshooting

If clients have trouble connecting or streaming:

1. Check browser console for WebRTC errors
2. Ensure you're using HTTPS in production (required for WebRTC)
3. For testing across networks, consider using Daily which provides TURN servers
4. Verify browser permissions for camera and microphone
