---
title: "SmallWebRTCTransport"
description: "A lightweight WebRTC transport for peer-to-peer audio and video communication in Pipecat"
---

## Overview

SmallWebRTCTransport enables peer-to-peer ("serverless") WebRTC connections between clients and your Pipecat application. It implements bidirectional audio, video and data channels using WebRTC for real-time communication. This transport is open source and self-contained, with no dependencies on any other infrastructure.

SmallWebRTCTransport is the default transport for the Pipecat examples and starter kits. It is heavily tested and can be used in production.

<Tip>
  For detailed notes on how to decide between using the SmallWebRTCTransport or
  other WebRTC transports like the DailyTransport, see [this
  post](https://www.daily.co/blog/you-dont-need-a-webrtc-server-for-your-voice-agents/).
</Tip>

<CardGroup cols={2}>
  <Card
    title="SmallWebRTCTransport API"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.transports.network.small_webrtc.html"
  >
    Transport methods and configuration options
  </Card>
  <Card
    title="SmallWebRTCConnection API"
    icon="code"
    href="https://reference-server.pipecat.ai/en/latest/api/pipecat.transports.network.webrtc_connection.html"
  >
    Connection management and signaling methods
  </Card>
  <Card
    title="Example Code"
    icon="play"
    href="https://github.com/pipecat-ai/pipecat-examples/tree/main/p2p-webrtc/voice-agent"
  >
    Working example with voice agent implementation
  </Card>
  <Card
    title="Official WebRTC Docs"
    icon="book"
    href="https://webrtc.org/getting-started/overview"
  >
    Learn more about WebRTC!
  </Card>
</CardGroup>

## Installation

To use `SmallWebRTCTransport`, install the required dependencies:

```bash
pip install "pipecat-ai[webrtc]"
```

No API keys are required since this is a peer-to-peer transport implementation.

<Tip>
  For production deployments across different networks, you may need to
  configure STUN/TURN servers for NAT traversal.
</Tip>

## Frames

### Input

- `InputAudioRawFrame` - Audio data from WebRTC peer
- `UserImageRawFrame` - Video frames from peer's camera
- `TransportMessageUrgentFrame` - Application messages from peer

### Output

- `OutputAudioRawFrame` - Audio data to WebRTC peer
- `OutputImageRawFrame` - Video frames to peer
- `TransportMessageFrame` - Application messages to peer
- `TransportMessageUrgentFrame` - Urgent messages to peer

## Key Features

- **Serverless Architecture**: Direct peer-to-peer connections with no intermediate servers
- **Bidirectional Media**: Full-duplex audio and video streaming
- **Data Channels**: Application messaging and signaling support
- **Production Ready**: Heavily tested and used in Pipecat examples
- **ICE Support**: Configurable STUN/TURN servers for NAT traversal

## Usage Example

SmallWebRTCTransport requires two components working together: a **signaling server** to handle the WebRTC handshake, and your **Pipecat bot** that processes the media streams. Unlike other transports, you cannot use SmallWebRTCTransport without implementing both parts.

### 1. Signaling Server (Required)

First, create a web server to handle WebRTC connection establishment. This server receives offers from clients and creates the WebRTC connections that your bot will use:

```python
import asyncio
from contextlib import asynccontextmanager
from typing import Dict

from fastapi import BackgroundTasks, FastAPI
from fastapi.responses import FileResponse
from pipecat.transports.network.webrtc_connection import IceServer, SmallWebRTCConnection

app = FastAPI()

# Store active WebRTC connections by their unique ID
connections: Dict[str, SmallWebRTCConnection] = {}

# Configure ICE servers for NAT traversal
ice_servers = [
    IceServer(urls="stun:stun.l.google.com:19302"),
]

@app.post("/api/offer")
async def handle_offer(request: dict, background_tasks: BackgroundTasks):
    """Handle WebRTC offer from client and return SDP answer."""
    pc_id = request.get("pc_id")

    if pc_id and pc_id in connections:
        # Handle reconnections
        webrtc_connection = connections[pc_id]
        await webrtc_connection.renegotiate(
            sdp=request["sdp"],
            type=request["type"]
        )
    else:
        # Create new WebRTC connection
        webrtc_connection = SmallWebRTCConnection(ice_servers=ice_servers)
        await webrtc_connection.initialize(
            sdp=request["sdp"],
            type=request["type"]
        )

        # Clean up when client disconnects
        @webrtc_connection.event_handler("closed")
        async def on_closed(connection):
            connections.pop(connection.pc_id, None)

        # Start bot for this connection (defined below)
        background_tasks.add_task(run_bot, webrtc_connection)

    answer = webrtc_connection.get_answer()
    connections[answer["pc_id"]] = webrtc_connection
    return answer

# Run with: uvicorn server:app --host 0.0.0.0 --port 7860
```

### 2. Pipecat Bot Implementation

Next, implement your bot function that receives the WebRTC connection from the server and creates the transport:

```python
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.pipeline.pipeline import Pipeline
from pipecat.transports.base_transport import TransportParams
from pipecat.transports.network.small_webrtc import SmallWebRTCTransport

async def run_bot(webrtc_connection):
    """Run the Pipecat bot for a specific WebRTC connection."""
    # Create transport using the connection from the server
    transport = SmallWebRTCTransport(
        webrtc_connection=webrtc_connection,
        params=TransportParams(
            audio_in_enabled=True,   # Accept audio from client
            audio_out_enabled=True,  # Send audio to client
            vad_analyzer=SileroVADAnalyzer(),
        ),
    )

    # Your services (STT, LLM, TTS, etc.)
    # ...

    # Create pipeline
    pipeline = Pipeline([
        transport.input(),              # Receive audio from client
        stt,                            # Convert speech to text
        context_aggregator.user(),      # Add user messages to context
        llm,                            # Process text with LLM
        tts,                            # Convert text to speech
        transport.output(),             # Send audio responses to client
        context_aggregator.assistant(), # Add assistant responses to context
    ])

    # Handle connection events
    @transport.event_handler("on_client_connected")
    async def on_client_connected(transport, client):
        # Start conversation when client connects
        await task.queue_frames([context_aggregator.user().get_context_frame()])

    @transport.event_handler("on_client_disconnected")
    async def on_client_disconnected(transport, client):
        await task.cancel()

    # Run the pipeline
    # ...
```

### How It Works Together

1. **Client connects** to your server at `/api/offer` with WebRTC offer
2. **Server creates** `SmallWebRTCConnection` and initializes it with the offer
3. **Server starts** `run_bot()` in background with the connection
4. **Bot creates** `SmallWebRTCTransport` using the connection
5. **Media flows** directly between client and bot via WebRTC peer connection

This architecture gives you the benefits of peer-to-peer WebRTC (low latency, no media servers) while maintaining a simple server for connection management.

## How to connect with SmallWebRTCTransport

For client connections, you have two options:

1. **Pipecat Client SDK** (Recommended): Use the [JavaScript SDK](/client/js/transports/small-webrtc) for easy integration
2. **Custom WebRTC Client**: Implement WebRTC signaling manually for advanced use cases

The server setup is shown in the [Usage Example](#usage-example) above.

## Examples

To see a complete implementation, check out the following examples:

<CardGroup>
  <Card
    title="Video Transform"
    icon="camera"
    href="https://github.com/pipecat-ai/pipecat-examples/tree/main/p2p-webrtc/video-transform"
  >
    Demonstrates real-time video processing using WebRTC transport
  </Card>
  <Card
    title="Voice Agent"
    icon="microphone"
    href="https://github.com/pipecat-ai/pipecat-examples/tree/main/p2p-webrtc/voice-agent"
  >
    Implements a voice assistant using WebRTC for audio communication
  </Card>
</CardGroup>

## Media Handling

### Audio

Audio is processed in 20ms chunks by default. The transport handles audio format conversion and resampling as needed:

- Input audio is processed at 16kHz (mono) to be compatible with speech recognition services
- Output audio can be configured to match your application's requirements, but it must be mono, 16-bit PCM audio

### Video

Video is streamed using RGB format by default. The transport provides:

- Frame conversion between different color formats (RGB, YUV, etc.)
- Configurable resolution and framerate

## WebRTC ICE Servers Configuration

When implementing WebRTC in your project, **STUN** (Session Traversal Utilities for NAT) and **TURN** (Traversal Using Relays around NAT)
servers are usually needed in cases where users are behind routers or firewalls.

In local networks (e.g., testing within the same home or office network), you usually don't need to configure STUN or TURN servers.
In such cases, WebRTC can often directly establish peer-to-peer connections without needing to traverse NAT or firewalls.

### What are STUN and TURN Servers?

- **STUN Server**: Helps clients discover their public IP address and port when they're behind a NAT (Network Address Translation) device (like a router).
  This allows WebRTC to attempt direct peer-to-peer communication by providing the public-facing IP and port.

- **TURN Server**: Used as a fallback when direct peer-to-peer communication isn't possible due to strict NATs or firewalls blocking connections.
  The TURN server relays media traffic between peers.

### Why are ICE Servers Important?

**ICE (Interactive Connectivity Establishment)** is a framework used by WebRTC to handle network traversal and NAT issues.
The `iceServers` configuration provides a list of **STUN** and **TURN** servers that WebRTC uses to find the best way to connect two peers.

## Advanced Configuration

### ICE Servers

For better connectivity, especially when testing across different networks, you can provide STUN servers:

```python
webrtc_connection = SmallWebRTCConnection(
    ice_servers=["stun:stun.l.google.com:19302", "stun:stun1.l.google.com:19302"]
)
```

You can also use IceServer objects for more advanced configuration:

```python
from pipecat.transports.network.webrtc_connection import IceServer

webrtc_connection = SmallWebRTCConnection(
    ice_servers=[
        IceServer(urls="stun:stun.l.google.com:19302"),
        IceServer(
            urls="turn:turn.example.com:3478",
            username="username",
            credential="password"
        )
    ]
)
```

## Troubleshooting

If clients have trouble connecting or streaming:

1. Check browser console for WebRTC errors
2. Ensure you're using HTTPS in production (required for WebRTC)
3. For testing across networks, consider using Daily which provides TURN servers
4. Verify browser permissions for camera and microphone
