---
title: "WebsocketServerTransport"
description: "WebSocket server transport implementation for real-time audio communication"
---

## Overview

`WebsocketServerTransport` provides a WebSocket server implementation for real-time audio communication. It supports bidirectional audio streams and voice activity detection (VAD).

<Warning>
WebsocketServerTransport is best suited for server-side applications and prototyping client/server apps.

For client/server production applications, we strongly recommend using a WebRTC-based transport
for robust network and media handling.

</Warning>

## Installation

To use `WebsocketServerTransport`, install the required dependencies:

```bash
pip install "pipecat-ai[websocket]"
```

## Configuration

### Constructor Parameters

<ParamField path="host" type="str" default="localhost">
  Host address to bind the WebSocket server
</ParamField>

<ParamField path="port" type="int" default="8765">
  Port number for the WebSocket server
</ParamField>

<ParamField
  path="params"
  type="WebsocketServerParams"
  default="WebsocketServerParams()"
>
  Transport configuration parameters
</ParamField>

### WebsocketServerParams Configuration

<ParamField path="add_wav_header" type="bool" default="False">
  Add WAV header to audio frames
</ParamField>

<ParamField
  path="serializer"
  type="FrameSerializer"
  default="ProtobufFrameSerializer()"
>
  Frame serializer for WebSocket messages
</ParamField>

<ParamField path="session_timeout" type="int | None" default="None">
  Session timeout in seconds. If set, triggers timeout event when no activity is
  detected
</ParamField>

#### Audio Configuration

<ParamField path="audio_in_enabled" type="bool" default={false}>
  Enable audio input from the WebRTC client
</ParamField>

<ParamField path="audio_in_passthrough" type="bool" default="False">
  When enabled, incoming audio frames are pushed downstream
</ParamField>

<ParamField path="audio_out_enabled" type="bool" default="False">
  Enable audio output capabilities
</ParamField>

<ParamField path="audio_out_sample_rate" type="int" default="None">
  Audio output sample rate in Hz
</ParamField>

<ParamField path="audio_out_channels" type="int" default="1">
  Number of audio output channels
</ParamField>

#### Voice Activity Detection (VAD)

<ParamField path="vad_analyzer" type="VADAnalyzer | None" default="None">
  Voice Activity Detection analyzer. You can set this to either
  `SileroVADAnalyzer()` or `WebRTCVADAnalyzer()`. SileroVADAnalyzer is the
  recommended option. Learn more about the
  [SileroVADAnalyzer](/server/utilities/audio/silero-vad-analyzer).
</ParamField>

## Basic Usage

```python
from pipecat.transports.network.websocket_server import (
    WebsocketServerTransport,
    WebsocketServerParams
)
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.pipeline.pipeline import Pipeline

# Configure transport
transport = WebsocketServerTransport(
    host="localhost",
    port=8765,
    params=WebsocketServerParams(
        audio_in_enabled=True,
        audio_out_enabled=True,
        add_wav_header=True,
        vad_analyzer=SileroVADAnalyzer(),
        session_timeout=180  # 3 minutes
    )
)

# Use in pipeline
pipeline = Pipeline([
    transport.input(),    # Handle incoming audio
    stt,          # Speech-to-text
    llm,          # Language model
    tts,          # Text-to-speech
    transport.output()    # Handle outgoing audio
])
```

<Tip>
  Check out the [Websocket Server
  example](https://github.com/pipecat-ai/pipecat-examples/tree/main/websocket-server)
  to see how to use this transport in a pipeline.
</Tip>

## Event Callbacks

WebsocketServerTransport provides callbacks for handling client connection events. Register callbacks using the `@transport.event_handler()` decorator.

### Connection Events

<ResponseField name="on_client_connected" type="async callback">
  Called when a client connects to the WebSocket server.

**Parameters:**

- `transport`: The WebsocketServerTransport instance
- `client`: WebSocket client connection object

```python
@transport.event_handler("on_client_connected")
async def on_client_connected(transport, client):
    logger.info(f"Client connected: {client.remote_address}")
    # Initialize conversation
    await task.queue_frames([LLMMessagesFrame(initial_messages)])
```

</ResponseField>

<ResponseField name="on_client_disconnected" type="async callback">
  Called when a client disconnects from the WebSocket server.

**Parameters:**

- `transport`: The WebsocketServerTransport instance
- `client`: WebSocket client connection object

```python
@transport.event_handler("on_client_disconnected")
async def on_client_disconnected(transport, client):
    logger.info(f"Client disconnected: {client.remote_address}")
```

</ResponseField>

<ResponseField name="on_session_timeout" type="async callback">
  Called when a session times out (if session_timeout is configured).

**Parameters:**

- `transport`: The WebsocketServerTransport instance
- `client`: WebSocket client connection object

```python
@transport.event_handler("on_session_timeout")
async def on_session_timeout(transport, client):
    logger.info(f"Session timeout for client: {client.remote_address}")
    # Handle timeout (e.g., send message, close connection)
```

</ResponseField>

## Frame Types

### Input Frames

<ParamField path="InputAudioRawFrame" type="Frame">
  Raw audio data from the WebSocket client
</ParamField>

### Output Frames

<ParamField path="OutputAudioRawFrame" type="Frame">
  Audio data to be sent to the WebSocket client
</ParamField>

## Notes

- Supports real-time audio communication
- Best suited for server-side applications
- Handles WebSocket connection management
- Provides voice activity detection
- Supports session timeouts
- Single client per server (new connections replace existing ones)
- All callbacks are asynchronous
