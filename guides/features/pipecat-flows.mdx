---
title: "Pipecat Flows"
description: "Learn how to create structured conversations using Pipecat's flow system"
---

## What is Pipecat Flows?

Pipecat Flows is an add-on framework for Pipecat that allows you to build structured conversations in your AI applications. It enables you to create both predefined conversation paths and dynamically generated flows while handling the complexities of state management and LLM interactions.

Want to dive right in? Check out these examples:

<CardGroup cols={2}>
  <Card
    title="Hello World"
    icon="rocket"
    href="https://github.com/pipecat-ai/pipecat-flows/tree/main/examples/quickstart"
  >
    A great first Flow to show you the ropes
  </Card>
  <Card
    title="Restaurant Reservation"
    icon="utensils"
    href="https://github.com/pipecat-ai/pipecat-flows/blob/main/examples/dynamic/restaurant_reservation.py"
  >
    A simple, practical dynamic flow example
  </Card>
</CardGroup>

## How do Pipecat and Pipecat Flows work together?

**Pipecat** defines the core capabilities of your bot. This includes the pipeline and processors which, at a minimum, enable your bot to:

- Receive audio from a user
- Transcribe the user's input
- Run an LLM completion
- Convert the LLM response to audio
- Send audio back to the user

**Pipecat Flows** complements Pipecat's core functionality by managing the conversation's context and tools. This is separate from the core pipeline, allowing you to separate the conversation logic from the LLM processing.

## When to Use Pipecat Flows?

Pipecat Flows is best suited for use cases where:

- You require precise control over how a conversation progresses
- Your bot needs to handle a complex task that can be decomposed into discrete steps
- You're trying to improve the accuracy of your LLM's response or tool use

Why is this effective? Flows provides a framework for breaking up long or monolithic prompts into discrete steps. This helps your LLM handle the most recent input (i.e. task) at a time.

## Selecting a Flows API

Pipecat Flows provides two APIs for how to build your application: Dynamic Flows and Static Flows.

- **Dynamic Flows (recommended)**: When conversation paths need to be determined at runtime based on user input, external data, or business logic.
- **Static Flows**: When your conversation structure is known upfront and follows predefined paths.

<Note>
  Dynamic Flows can handle both simple and complex use cases. Selecting it
  provides you with an option that can grow with the complexity of your
  application. For these reasons, we strongly recommend it as the API pattern to
  follow.
</Note>

## Technical Overview

Pipecat Flows represents conversations as graphs, where each step of the conversation is represented by a node. Nodes are typed as a `NodeConfig`, which may contain the following fields:

- `name`: The name of the node
- `role_messages`: A list of message `dicts` defining the bot's role/personality
- `task_messages`: A list of message `dicts` defining the current node's objectives
- `functions`: List of function definitions in either a provider-specific format or a FlowsFunctionSchema
- `pre_actions`: Actions to execute before LLM inference. Actions run once upon transitioning to a node
- `post_actions`: Actions to execute after LLM inference. Actions run once after the node's initial LLM inference
- `context_strategy`: Strategy for updating context during transitions. The default behavior is to append messages to the context
- `respond_immediately`: Whether to run LLM inference as soon as the node is set. The default is True

<Info>
  The only required field is `task_messages`, as your bot always needs a prompt
  to advance the conversation.
</Info>

### Messages

Messages define the persona and task of a given node. Messages are specified in OpenAI format as a list of `dicts`. For example:

```python
"role_messages": [
    {
        "role": "system",
        "content": "You are an inquisitive child.",
    }
],
"task_messages": [
    {
        "role": "user",
        "content": "Say 'Hello world' and ask what is the user's favorite color.",
    }
],
```

The message format is translated by Pipecat to/from the message format of the LLM in your Pipecat pipeline, making it easy to switch between LLM providers.

<Warning>
  Some LLMs, like Anthropic and Gemini, can only set the system instruction at
  initialization time. This means you will only be able to set the
  `role_messages` at initialization.
</Warning>

### Functions

Function calls serve two purposes:

1. An interface with external systems and APIs to read or write information
2. The mechanism to navigate the graph

When constructing your nodes, be sure to clearly define the task for a given node. For example, if the job is to retrieve a user's favorite color, the LLM can directly ask the question and upon receiving the answer, it can call the function. Calling the function signals to Flows that the task is complete and time to transition to the next node.

Flows provides a universal schema to allow for function calls to work across different LLM providers. This schema is called the `FlowsFunctionSchema`. For example:

```python
record_favorite_color_func = FlowsFunctionSchema(
    name="record_favorite_color_func",
    description="Record the color the user said is their favorite.",
    required=["color"],
    handler=record_favorite_color_and_set_next_node,
    properties={"color": {"type": "string"}},
)
```

Functions have a corresponding `handler`, specified in the FlowsFunctionSchema. The `handler` is where you execute your application's logic and tell Flows how to transition to the next node.

```python
async def record_favorite_color_and_set_next_node(
    args: FlowArgs, flow_manager: FlowManager
) -> tuple[str, NodeConfig]:
    """Function handler that records the color then sets the next node.

    Here "record" means print to the console, but any logic could go here;
    Write to a database, make an API call, etc.
    """
    print(f"Your favorite color is: {args['color']}")
    return args["color"], create_end_node()
```

Handlers should return a Tuple, containing:

- A result, which is provided to the LLM for a subsequent completion
- The next node for Flows to transition to

### Actions

Actions let you execute custom functionality upon transitioning to a new node:

- `pre_actions`: Pre-actions run once upon transitioning to a new node _before_ the LLM inference
- `post_actions`: Post-actions run once upon transitioning to a new node _after_ the LLM inference

There are built-in actions to make it easy to do common things like:

- `tts_say`: Say a phrase
- `end_conversation`: End the pipeline
- `function`: Run a function

You can also define your own custom action. See the usage examples below for more details.

### Context Strategy

Flows provides three built-in ways to manage the context:

1. **APPEND**: By default, new nodes are appended to the context. This means that the context grows as the conversation progresses. This ensures that your bot has access to the conversation history.
2. **RESET**: When transitioning to a node with the `RESET` strategy, the context is first reset then the node's `role_messages` and `task_messages` are applied. This can be useful when the previous conversation history is no longer relevant. It can help to reduce the context window size and help the LLM focus due to the smaller context window.
3. **RESET_WITH_SUMMARY**: When transitioning to a node with the `RESET_WITH_SUMMARY` strategy, the context is first summarized then updated to include the conversation summary and new node messages. This is also helpful in reducing the context window size and focusing the bot while not losing the conversation history.

### Respond Immediately

For each node in the conversation, you can decide whether the LLM should respond immediately upon entering the node (the default behavior) or whether the LLM should wait for the user to speak first before responding. You do this using the `respond_immediately` field.

<Tip>
  `respond_immediately=False` may be particularly useful in the very first node,
  especially in outbound-calling cases where the user has to first answer the
  phone to trigger the conversation.
</Tip>

```python
NodeConfig(
    task_messages=[
        {
            "role": "system",
            "content": "Warmly greet the customer and ask how many people are in their party. This is your only job for now; if the customer asks for something else, politely remind them you can't do it.",
        }
    ],
    respond_immediately=False,
    # ... other fields
)
```

<Warning>
  Keep in mind that if you specify `respond_immediately=False`, the user may not
  be aware of the conversational task at hand when entering the node (the bot
  hasn't told them yet). While it's always important to have guardrails in your
  node messages to keep the conversation on topic, letting the user speak first
  makes it even more so.
</Warning>

## Initialization

Flows are initialized in the core Pipecat file by first creating the `FlowManager` instance and later calling `initialize()` to start the flow.

### Dynamic Flow

First, create the FlowManager:

```python
flow_manager = FlowManager(
    task=task,                              # PipelineTask
    llm=llm,                                # LLMService
    context_aggregator=context_aggregator,  # Context aggregator
    transport=transport,                    # Transport
)
```

Then initialize by passing the initial `NodeConfig` into the `initialize()` method:

```python
@transport.event_handler("on_client_connected")
async def on_client_connected(transport, client):
    logger.info(f"Client connected")
    # Kick off the conversation.
    await flow_manager.initialize(create_initial_node())
```

### Static Flow

First, create the FlowManager:

```python
flow_manager = FlowManager(
    task=task,                              # PipelineTask
    llm=llm,                                # LLMService
    context_aggregator=context_aggregator,  # Context aggregator
    flow_config=flow_config,                # FlowConfig
)
```

Then initialize:

```python
@transport.event_handler("on_first_participant_joined")
async def on_first_participant_joined(transport, participant):
    await transport.capture_participant_transcription(participant["id"])
    logger.debug("Initializing flow")
    await flow_manager.initialize()
```

<Note>For Static Flows, `initialize()` does not take any args.</Note>

## State Management

In addition to the nodes, Flows comes equipped with built-in state management. The `state` variable in `FlowManager` is a shared dictionary that persists throughout the conversation. Think of it as a conversation memory that lets you store application information across nodes with a common reference.

For example:

```python
async def record_favorite_color_and_set_next_node(
    args: FlowArgs, flow_manager: FlowManager
) -> tuple[str, NodeConfig]:
    """Function handler that records the color then sets the next node.

    Here "record" means print to the console, but any logic could go here;
    Write to a database, make an API call, etc.
    """
    flow_manager.state["color"] = args["color"]
    print(f"Your favorite color is: {args['color']}")
    return args["color"], create_end_node()
```

## Usage Examples

### NodeConfig (Dynamic Flow)

The `NodeConfig` defines the type of a given node. For dynamic flows, you would write a function that defines the node and returns a NodeConfig.

```python
def create_initial_node() -> NodeConfig:
    """Create the initial node of the flow.

    Define the bot's role and task for the node as well as the function for it to call.
    The function call includes a handler which provides the function call result to
    Pipecat and then transitions to the next node.
    """
    record_favorite_color_func = FlowsFunctionSchema(
        name="record_favorite_color_func",
        description="Record the color the user said is their favorite.",
        required=["color"],
        handler=record_favorite_color_and_set_next_node,
        properties={"color": {"type": "string"}},
    )

    return {
        "name": "initial",
        "role_messages": [
            {
                "role": "system",
                "content": "You are an inquisitive child. Use very simple language. Ask simple questions. You must ALWAYS use one of the available functions to progress the conversation. Your responses will be converted to audio. Avoid outputting special characters and emojis.",
            }
        ],
        "task_messages": [
            {
                "role": "system",
                "content": "Say 'Hello world' and ask what is the user's favorite color.",
            }
        ],
        "functions": [record_favorite_color_func],
    }
```

### FlowConfig (Static Flow)

The FlowConfig is a static JSON object that completely defines the entire flow. This follows the same rules as the NodeConfig, but is assembled as a single JSON object that defines the entire state of the program.

The FlowConfig can contain functions that are used to define the function handler behavior that executes when a function call occurs.

See the [food_ordering example](https://github.com/pipecat-ai/pipecat-flows/blob/main/examples/static/food_ordering.py) for an example of the FlowConfig.

### Function Calls

Pipecat Flows supports three ways to define function calls:

#### 1. FlowsFunctionSchema (Recommended)

Provider agnostic function call definition that works across all LLM providers:

```python
from pipecat_flows import FlowsFunctionSchema

collect_info_func = FlowsFunctionSchema(
    name="collect_user_info",
    description="Collect basic user information",
    required=["name", "email"],
    handler=process_user_info,
    properties={
        "name": {"type": "string"},
        "email": {"type": "string", "format": "email"}
    },
)
```

#### 2. FlowsDirectFunction

Consolidates the function definition and handler logic into a single function. The function signature and docstring are automatically used to generate the function schema:

```python
async def collect_user_info(
    flow_manager: FlowManager,
    name: str,
    email: str
) -> tuple[FlowResult, NodeConfig]:
    """
    Collect basic user information.

    Args:
        name (str): The user's full name
        email (str): The user's email address
    """
    # Process the information
    flow_manager.state["user_info"] = {"name": name, "email": email}

    # Return result and next node
    return {"status": "success"}, create_next_node()

# Use directly in NodeConfig
node_config = {
    "functions": [collect_user_info]
}
```

#### 3. Provider Native Format

Uses the provider's native format (OpenAI, Anthropic, etc.). While supported, we recommend using FlowsFunctionSchema for better portability.

### Actions

#### Built-in Actions

Use built-in actions for common operations:

```python
# End conversation action
"post_actions": [
    {
        "type": "end_conversation",
        "text": "Thank you for your time!"
    }
]

# TTS say action
"pre_actions": [
    {
        "type": "tts_say",
        "text": "Please hold while I process your request..."
    }
]
```

#### Custom Actions

Build custom actions for specific needs:

```python
"pre_actions": [
    {
        "type": "check_kitchen",
        "handler": check_kitchen_status,
    },
]
```

Corresponding function:

```python
async def check_kitchen_status(action: dict) -> None:
    """Check if kitchen is open and log status."""
    logger.info("Checking kitchen status")
    # Custom logic here
```

### Context Strategy

Context strategies can be defined globally in the FlowManager constructor or on a per-node basis:

```python
from pipecat_flows import ContextStrategy, ContextStrategyConfig

# Global strategy configuration
flow_manager = FlowManager(
    task=task,
    llm=llm,
    context_aggregator=context_aggregator,
    context_strategy=ContextStrategyConfig(
        strategy=ContextStrategy.APPEND,
    )
)

# Per-node strategy configuration
node_config = {
    "task_messages": [...],
    "functions": [...],
    "context_strategy": ContextStrategyConfig(
        strategy=ContextStrategy.RESET_WITH_SUMMARY,
        summary_prompt="Provide a concise summary of the customer's order details and preferences."
    )
}
```

## Next Steps

Now that you understand the basics of Pipecat Flows, explore the examples in the repository to see complete implementations:

- [Hello World Example](https://github.com/pipecat-ai/pipecat-flows/tree/main/examples/quickstart) - Start here for your first flow
- [Restaurant Reservation](https://github.com/pipecat-ai/pipecat-flows/blob/main/examples/dynamic/restaurant_reservation.py) - Dynamic flow with external API integration
- [More Examples](https://github.com/pipecat-ai/pipecat-flows/tree/main/examples) - Additional static and dynamic flow examples

```

```
